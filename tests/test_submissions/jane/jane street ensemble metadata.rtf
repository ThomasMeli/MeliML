{\rtf1\ansi\ansicpg1252\cocoartf2577
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww13400\viewh9980\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \
\'97\
\
For ease: you can \'93extract the test data\'94 and your output submission and train your model on that to simplify the code.\
\
\'97\
\
Remember, when ensembling you will have to replicate the entire code pipeline and any important objects.\
\
\'97\
\
submission0:\
https://www.kaggle.com/aimind/bottleneck-encoder-mlp-keras-tuner-8601c5\
\
submission1:\
https://www.kaggle.com/finlay/encoder-mlp\
\
submission2:\
https://www.kaggle.com/lpachuong/fork-of-notebookd9779f8f26\
\
submission3:\
https://www.kaggle.com/binhlc/jane-street-tensorflow-dense\
\
submission4:\
https://www.kaggle.com/manavtrivedi/gaussiandenoised-deepnn-model\
\
submission5:\
https://www.kaggle.com/code1110/janestreet-1dcnn-for-feature-extraction-infer}